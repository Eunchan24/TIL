{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import datasets \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(input_shape)\n",
    "\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is the full model w/o custom layers\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
    "              loss='sparse_categorical_crossentropy',  # Loss Function \n",
    "              metrics=['accuracy'])  # Metrics / Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths = glob('/Users/eunchankim/Desktop/dataset/cifar/train/*.png')\n",
    "test_paths = glob('/Users/eunchankim/Desktop/dataset/cifar/test/*.png')\n",
    "\n",
    "len(train_paths), len(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(path):\n",
    "    return path.split('_')[-1].replace('.png', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [get_class_name(path) for path in train_paths]\n",
    "class_names = np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path):\n",
    "    fname = tf.strings.split(path, '_')[-1]\n",
    "    lbl_name = tf.strings.regex_replace(fname, '.png', '')\n",
    "    onehot = tf.cast(lbl_name == class_names, tf.uint8)\n",
    "    return tf.argmax(onehot)  # 이번에는 onehot이 아닌 label 번호로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_label(path):\n",
    "    gfile = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.cast(image, tf.float32) / 255.  # rescale\n",
    "    \n",
    "    label = get_label(path)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(image, label):\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function get_label at 0x10eb86550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function get_label at 0x10eb86550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_dataset = train_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(image_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_paths))\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "test_dataset = test_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(save_path, monitor='val_accuracy', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tf1/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1562/1562 [==============================] - 44s 18ms/step - loss: 1.9774 - accuracy: 0.2659 - val_loss: 1.5233 - val_accuracy: 0.4421\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44211, saving model to checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tf1/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tf1/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1397: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`layer.updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "Epoch 2/20\n",
      "1562/1562 [==============================] - 27s 18ms/step - loss: 1.7360 - accuracy: 0.3877 - val_loss: 1.4735 - val_accuracy: 0.4590\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.44211 to 0.45903, saving model to checkpoints\n",
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "Epoch 3/20\n",
      "1562/1562 [==============================] - 28s 18ms/step - loss: 1.8509 - accuracy: 0.3927 - val_loss: 1.4091 - val_accuracy: 0.4886\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.45903 to 0.48858, saving model to checkpoints\n",
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n",
      "Epoch 4/20\n",
      "1562/1562 [==============================] - 28s 18ms/step - loss: 1.9868 - accuracy: 0.3854 - val_loss: 1.7749 - val_accuracy: 0.4273\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.48858\n",
      "Epoch 5/20\n",
      "1562/1562 [==============================] - 29s 19ms/step - loss: 2.1831 - accuracy: 0.3729 - val_loss: 1.7002 - val_accuracy: 0.4141\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.48858\n",
      "Epoch 6/20\n",
      "1562/1562 [==============================] - 29s 18ms/step - loss: 2.4765 - accuracy: 0.3665 - val_loss: 2.7953 - val_accuracy: 0.3287\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.48858\n",
      "Epoch 7/20\n",
      "1562/1562 [==============================] - 30s 19ms/step - loss: 3.6282 - accuracy: 0.3135 - val_loss: 2.8100 - val_accuracy: 0.2604\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.48858\n",
      "Epoch 8/20\n",
      "1562/1562 [==============================] - 29s 19ms/step - loss: 6.3057 - accuracy: 0.2370 - val_loss: 4.9466 - val_accuracy: 0.2648\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.48858\n",
      "Epoch 9/20\n",
      "1562/1562 [==============================] - 28s 18ms/step - loss: 16.9274 - accuracy: 0.2085 - val_loss: 2.3844 - val_accuracy: 0.1132\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.48858\n",
      "Epoch 10/20\n",
      "1562/1562 [==============================] - 29s 18ms/step - loss: 28.2579 - accuracy: 0.1591 - val_loss: 49.1528 - val_accuracy: 0.2078\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.48858\n",
      "Epoch 11/20\n",
      "1562/1562 [==============================] - 28s 18ms/step - loss: 127.4533 - accuracy: 0.1923 - val_loss: 211.8614 - val_accuracy: 0.2662\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.48858\n",
      "Epoch 12/20\n",
      "1562/1562 [==============================] - 28s 18ms/step - loss: 288.2148 - accuracy: 0.1896 - val_loss: 324.8067 - val_accuracy: 0.2268\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.48858\n",
      "Epoch 13/20\n",
      "1562/1562 [==============================] - 28s 18ms/step - loss: 391.3941 - accuracy: 0.2100 - val_loss: 438.3449 - val_accuracy: 0.2674\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.48858\n",
      "Epoch 14/20\n",
      "1562/1562 [==============================] - 28s 18ms/step - loss: 716.3077 - accuracy: 0.2026 - val_loss: 446.7054 - val_accuracy: 0.2835\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.48858\n",
      "Epoch 15/20\n",
      "1562/1562 [==============================] - 28s 18ms/step - loss: 1179.9696 - accuracy: 0.2140 - val_loss: 491.0153 - val_accuracy: 0.1964\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.48858\n",
      "Epoch 16/20\n",
      "1562/1562 [==============================] - 29s 18ms/step - loss: 1743.2908 - accuracy: 0.2042 - val_loss: 1598.1565 - val_accuracy: 0.2660\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.48858\n",
      "Epoch 17/20\n",
      "1562/1562 [==============================] - 29s 18ms/step - loss: 2892.9020 - accuracy: 0.2050 - val_loss: 2653.9104 - val_accuracy: 0.2798\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.48858\n",
      "Epoch 18/20\n",
      "1562/1562 [==============================] - 28s 18ms/step - loss: 3746.6198 - accuracy: 0.2078 - val_loss: 1915.6757 - val_accuracy: 0.2684\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.48858\n",
      "Epoch 19/20\n",
      "1562/1562 [==============================] - 28s 18ms/step - loss: 5750.0745 - accuracy: 0.2085 - val_loss: 2083.7773 - val_accuracy: 0.2575\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.48858\n",
      "Epoch 20/20\n",
      "1562/1562 [==============================] - 28s 18ms/step - loss: 6683.9969 - accuracy: 0.2159 - val_loss: 3207.7380 - val_accuracy: 0.2568\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.48858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x297da8e50>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train_paths) // batch_size\n",
    "validation_steps = len(test_paths) // batch_size\n",
    "\n",
    "model.fit_generator(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tensorboard/r2/image_summaries#setup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
