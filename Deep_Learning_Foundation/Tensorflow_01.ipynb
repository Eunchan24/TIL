{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorboardX\n",
    "#!pip install jupyter-tensorboard\n",
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "# !pip install h5py\n",
    "# !python3 -m pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.임포트 \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[12]], shape=(1, 1), dtype=int32)\n",
      "tf.Tensor([ 1  4  9 16], shape=(4,), dtype=int32)\n",
      "tf.Tensor([2 4 6 8], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#2. 행과 열을 만들자\n",
    "matrix1 = tf.constant([[3,3] ])\n",
    "matrix1\n",
    "\n",
    "matrix2 = tf.constant([[2],[2] ])\n",
    "matrix2\n",
    "\n",
    "res = tf.matmul(matrix1, matrix2)\n",
    "print(res)\n",
    "#tf.constant([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "x = tf.constant([1, 2, 3, 4])\n",
    "res02= tf.multiply(x,x)\n",
    "print(res02)\n",
    "\n",
    "hap = tf.add(x,x)\n",
    "print(hap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([7.], shape=(1,), dtype=float32)\n",
      "tf.Tensor([21.], shape=(1,), dtype=float32)\n",
      "tf.Tensor([21.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#행렬 연산을 구현해보자 \n",
    "input01 = tf.constant([3.0])\n",
    "input02 = tf.constant([2.0])\n",
    "input03 = tf.constant([5.0])\n",
    "\n",
    "hap = tf.add(input02, input03)\n",
    "res = tf.multiply(input01, hap)\n",
    "print(hap)\n",
    "print(res)\n",
    "\n",
    "#중첩가능한지 확인\n",
    "res02 = tf.multiply(input01, tf.add(input02, input03))\n",
    "print(res02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello[[4]]\n",
      "hello,[[4]]\n"
     ]
    }
   ],
   "source": [
    "#3.즉시 기본 실행\n",
    "tf.executing_eagerly()\n",
    "x =[[2]]\n",
    "m = tf.multiply(x,x)\n",
    "print(f'hello{m}')\n",
    "print('hello,{}'.format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "(2, 2)\n",
      "<dtype: 'int32'> <class 'tensorflow.python.framework.dtypes.DType'>\n",
      "int32 <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#4. 반환작업\n",
    "a = tf.constant([[1,2],[3,4]])\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.dtype, type(a.dtype))\n",
    "print(a.numpy().dtype, type(a.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2  6]\n",
      " [12 20]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#5. 브로드케스팅 (Broadcasting) 지원\n",
    "b = tf.add(a,1)\n",
    "print(b)\n",
    "\n",
    "#6. 연산자 오버로딩\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6]\n",
      " [12 20]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Numpy 지원\n",
    "import numpy as np\n",
    "res = np.multiply(a,b)\n",
    "print(res , type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xed\\x99\\x8d\\xea\\xb8\\xb8\\xeb\\x8f\\x99'\n",
      "190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([b'\\xed\\x99\\x8d\\xea\\xb8\\xb8\\xeb\\x8f\\x99'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable\n",
    "name = tf.Variable(\"홍길동\", tf.string)\n",
    "kor = tf.Variable(100, tf.int32)\n",
    "eng = tf.Variable(90, tf.int32)\n",
    "tot = kor + eng\n",
    "print(name.numpy())\n",
    "print(tot.numpy())\n",
    "name02 = tf.Variable([\"홍길동\"], tf.string)\n",
    "name02.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12345.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable([3,12345,2.3295], tf.float32)\n",
    "b = tf.Variable([1,2,3,4,5],tf.int32)\n",
    "c = tf.Variable([12.3-4.85j, 7.5-6.12j], tf.complex64)\n",
    "a,b,c\n",
    "a.numpy(), b.numpy(), c.numpy()\n",
    "a.numpy()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor 차원을 리턴 받자 tf.zeros(), tf.rank()\n",
    "# 배치 *높이 * 너비 *색상\n",
    "my_img = tf.zeros([10,299,299,3])\n",
    "res = tf.rank(my_img)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# 요소를 리턴\n",
    "my_v = tf.Variable([1,2,3,4])\n",
    "my_s = my_v[2]\n",
    "print(my_s.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf의 객체를 Variable로 연동해보자 \n",
    "my_val = tf.Variable(tf.zeros([2,2,3])) #상수\n",
    "my_val.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf의 객체를 Variable로 연동해보자 \n",
    "my_val = tf.constant(tf.zeros([2,2,3])) #변수\n",
    "my_val.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>\n"
     ]
    }
   ],
   "source": [
    "# 변수 자동변환\n",
    "v = tf.Variable(0.0)\n",
    "v.numpy()\n",
    "\n",
    "w = v+1 \n",
    "w\n",
    "\n",
    "v = tf.Variable(0.0)\n",
    "v.assign_add(1)\n",
    "print(v.read_value())\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n",
      "[[-1. -2.]\n",
      " [-3. -4.]\n",
      " [-5. -6.]]\n",
      "[[-1. -2.]\n",
      " [-3. -4.]\n",
      " [-5. -6.]]\n",
      "[[ 0.13852419  0.17976241]\n",
      " [ 0.13863638  0.19217838]\n",
      " [-0.15452793  0.04327468]]\n",
      "[[-0.56239986  2.5044527 ]\n",
      " [-0.47417617 -2.337158  ]\n",
      " [ 4.6500998   3.9490402 ]]\n"
     ]
    }
   ],
   "source": [
    "#3*2행의 float32값을 이용해서 값을 구현해보자\n",
    "a = tf.Variable([[1,2],[3,4],[5,6]], dtype = tf.float32)\n",
    "print(a.numpy())\n",
    "\n",
    "#전체 -값으로 변경해보자\n",
    "a.assign([[-1,-2],[-3,-4],[-5,-6]])\n",
    "print(a.numpy())\n",
    "\n",
    "#3*2행의 값을 모두 0으로 초기화 float32\n",
    "b = tf.Variable(tf.zeros([3,2]), dtype = tf.float32)\n",
    "print(a.numpy())\n",
    "\n",
    "#3*2의 행의 값을 요소모두의 평균은 0, 표준편차 0.1의 정규 난수로 초기화를 시켜봐라\n",
    "#tf.random_normal_initializer(mean=0.0, stddev=0.05, seed=None)\n",
    "#tf.random.normal(shape, mean=0.0, stddev=1.0, dtype=tf.dtypes.float32, seed=None, name=None)\n",
    "a = tf.Variable(tf.random.normal([3,2], mean=0.0, stddev=0.1, dtype = tf.dtypes.float32))\n",
    "print(a.numpy())\n",
    "\n",
    "#3*2의 행의 값을 요소모두를 -1~3까지의 범위의 균일 값을 난수로 초기화 시켜라\n",
    "a = tf.Variable(tf.random.normal([3,2], mean=1, stddev=3, dtype = tf.dtypes.float32))\n",
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.6931472 1.0986123]\n",
      "[0.7615942 0.9640276 0.9950547]\n",
      "[0.7310586  0.8807971  0.95257413]\n",
      "[0.84147096 0.9092974  0.14112   ]\n"
     ]
    }
   ],
   "source": [
    "# f(x) 표현하는 연산 시스템\n",
    "# log(x), exp(x), sin(x), cos(x), sigmoid(x), tanh(x)등\n",
    "\n",
    "a = tf.constant([1,2,3], tf.float32)\n",
    "b = tf.math.log(a)\n",
    "print(b.numpy())\n",
    "\n",
    "b = tf.math.tanh(a)\n",
    "print(b.numpy())\n",
    "\n",
    "b = tf.math.sigmoid(a)\n",
    "print(b.numpy())\n",
    "\n",
    "\n",
    "b = tf.math.sin(a)\n",
    "print(b.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax : 로지스틱함수를 다차원으로 만든것\n",
    "\n",
    "다항 로지스틱 회귀로 출력에 대한 확률분포로 네트워크 출력을 하는 정규화 \n",
    "\n",
    "신경망의 활성화 홤수로 자주 사용된다. (one-hot)\n",
    "\n",
    "z = K로 실수값을 벡터를 받아서 입력숫자에 지수에 비례하는 K개의 확률 분포를 정규화 시킨것\n",
    "\n",
    "    tf.nn.softmax(logits, axis=None, name=None)\n",
    "    softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
    "\n",
    "    tf.nn.softmax(x)\n",
    "    입력 인수 x : 텐서, 정수 상수 텐서, 변수 상수\n",
    "    출력 값\n",
    "        1. x의 각 요소마다 exp()을 계산에서 A에 할당\n",
    "        2. A의 요소를 모두 더해서 임의변수 a에 넣는다.\n",
    "        3. A의 요소를 a로 나누어서 출력 텐서를 한다.\n",
    "        4. 출력 텐서의 각 요소의 값은 확률을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09003057 0.24472848 0.66524094]\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant([1,2,3],tf.float32)\n",
    "B = tf.nn.softmax(A)\n",
    "print(B.numpy()) #확률 분포\n",
    "\n",
    "B = tf.reduce_sum(A)\n",
    "print(B.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([20. 36.], shape=(2,), dtype=float32) <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[20. 36.]\n"
     ]
    }
   ],
   "source": [
    "#사용자 오퍼레이션 만드는법 \n",
    "'''\n",
    "    @tf.funtion\n",
    "    def 함수명():\n",
    "        연산\n",
    "        return\n",
    "'''\n",
    "\n",
    "#(a+b)*c mpOP(a,b,c)\n",
    "@tf.function\n",
    "def myOP(a,b,c):\n",
    "    t = tf.math.add(a,b)\n",
    "    return tf.math.multiply(t,c)\n",
    "\n",
    "A = tf.constant([1,2], tf.float32)\n",
    "\n",
    "B = tf.constant([3,4], tf.float32)\n",
    "\n",
    "C = tf.constant([5,6], tf.float32)\n",
    "\n",
    "d = myOP(a,b,c)\n",
    "print(d, type(d))\n",
    "print(d.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=10.0>, <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=2>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=4>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=5>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=6>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=7>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=8>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=9>)\n",
      "<__main__.MyModuleOne object at 0x00000222C3369250>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=10.0>\n"
     ]
    }
   ],
   "source": [
    "# 사용자 자료형 만들기\n",
    "# tf.Module를 상속받아구현한다\n",
    "# tf.Module 인스턴스는 Variable을 포함해서 다른 모듈들을 탐색할 수 있다. \n",
    "# trainable_variables = 훈련가능한 변수를 리턴\n",
    "\n",
    "class MyModuleOne(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.V0 = tf.Variable(1.0)\n",
    "        self.Vs = [tf.Variable(x) for x in range(10)]\n",
    "class MyOtherModule(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.m = MyModuleOne()\n",
    "        self.v = tf.Variable(10.0)\n",
    "        \n",
    "m = MyOtherModule()\n",
    "len(m.variables)\n",
    "print(m.variables)\n",
    "print(m.m)\n",
    "print(m.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#케라스\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(4, name=\"layer3\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.layers.core.Dense'>\n",
      "Layer_0\n",
      "{'Layer_0': 0, 'Layer_1': 1, 'Layer_2': 2}\n",
      "1\n",
      "1\n",
      "['Layer_0', 'Layer_1', 'Layer_2']\n"
     ]
    }
   ],
   "source": [
    "# 순차모델을 만들어보자\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, name = 'Layer_0', input_shape = (1000,)),\n",
    "    tf.keras.layers.Dense(10, name = 'Layer_1'),\n",
    "    tf.keras.layers.Dense(1, name = 'Layer_2'),\n",
    "])\n",
    "\n",
    "#model.summary()\n",
    "print(type(model.layers[0]))\n",
    "print(model.layers[0].name)\n",
    "\n",
    "\n",
    "\n",
    "d = {k.name : i for i, k in enumerate(model.layers)}\n",
    "print(d)\n",
    "print(d['Layer_1'])\n",
    "print(d.get('Layer_1'))\n",
    "\n",
    "layer_name = [k.name for k in model.layers]\n",
    "print(layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "심층 신경망은 학습한 모든 변환을 수치 데이터 텐서 연산을 사용한다.\n",
    "ex)텐서 덧셈, 텐서 곱셈\n",
    "\n",
    "tf.keras.layers.Dense(1, name='Layer_2') -> 신경망을 만들었다. 층을 설정했다.\n",
    "\n",
    "    데이터 -> 학습구조모델링 -> 학습 수행 -> 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[ 3  5  7  9 11]\n",
      "y: [ 3  5  7  9 11] predict: [ 2.9999883  4.9999933  6.9999986  9.000004  11.000009 ]\n"
     ]
    }
   ],
   "source": [
    "# 간단한 공식을 이용해서 값을 전달한 후 평가로 예측 값을 구현해보자\n",
    "\n",
    "#데이터\n",
    "# y =ax +b\n",
    "x = np.array([1,2,3,4,5])\n",
    "y = x*2+1\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "\n",
    "# 학습구조 모델링\n",
    "model = tf.keras.Sequential() #레이어를 층층히 쌓아주는 메소드\n",
    "model.add(layers.Dense(1, input_shape=(1,)))\n",
    "\n",
    "model.compile('SGD','mse')\n",
    "\n",
    "#SGD (Stochastic gradient descent : 확률적 경사 하강법)\n",
    "# mse(Mean Squared Error: 평균 제곱 오차)\n",
    "\n",
    "# 학습수행 \n",
    "model.fit(x,y, epochs=10000, verbose=0)\n",
    "\n",
    "#평가\n",
    "print('y:',y,'predict:',model.predict(x).flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8.0, shape=(), dtype=float32)\n",
      "tf.Tensor(8.0, shape=(), dtype=float32)\n",
      "tf.Tensor(8.0, shape=(), dtype=float32)\n",
      "tf.Tensor(8.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.GradientTape API : 텐서플로는 자동 미분하는 API를 제공한다.\n",
    "# context 안에 실행된 모든 연산을 tape에 기록한다.\n",
    "# 후진방식 자동미분을 사용해서 tape에 기록된 연산을 결과를 계산한다.\n",
    "\n",
    "x = tf.ones((2,2))\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "    t.watch(x)\n",
    "    y = tf.reduce_sum(x)\n",
    "    z = tf.multiply(y,y)\n",
    "    \n",
    "dz_dx = t.gradient(z,x)\n",
    "for i in [0,1]:\n",
    "    for j in [0,1]:\n",
    "        dz_dx[i][j].numpy() == 8.0\n",
    "        print(dz_dx[i][j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
